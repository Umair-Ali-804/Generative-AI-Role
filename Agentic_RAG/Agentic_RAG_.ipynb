{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-openai\n",
        "!pip install chromadb sentence-transformers\n",
        "!pip install pypdf pydantic\n",
        "!pip install faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehw8qyb3RthY",
        "outputId": "bbdf657b-0cab-4d7e-9ce8-435d9578444c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.6)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.14.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.50.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (35.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=24.0 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install"
      ],
      "metadata": {
        "id": "k8Wm0h145Au0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh6-Z0FcxIn5",
        "outputId": "5aa15cf3-e45a-4076-b024-14abc4152a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import List, Dict, Any, Optional, Literal\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_classic.schema import Document\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Pydantic for structured outputs\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Standard library\n",
        "import json\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "class RAGConfig:\n",
        "    OPENAI_API_KEY = \"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\"\n",
        "\n",
        "    BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "    LLM_MODEL = \"liquid/lfm-2.5-1.2b-thinking:free\"\n",
        "    LLM_TEMPERATURE = 0.2\n",
        "\n",
        "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "    VECTOR_DB_TYPE = \"chroma\"\n",
        "    PERSIST_DIRECTORY = \"./chroma_db\"\n",
        "    COLLECTION_NAME = \"agentic_rag_docs\"\n",
        "\n",
        "    CHUNK_SIZE = 1000\n",
        "    CHUNK_OVERLAP = 200\n",
        "\n",
        "    TOP_K_DOCUMENTS = 5\n",
        "    SIMILARITY_THRESHOLD = 0.7\n",
        "\n",
        "    MAX_ITERATIONS = 5\n",
        "    ENABLE_SELF_CORRECTION = True\n",
        "    ENABLE_QUERY_DECOMPOSITION = True\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = RAGConfig.OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "9J7u-Hy77rWj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "from enum import Enum\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class QueryType(str, Enum):\n",
        "    SIMPLE_FACTUAL = \"simple_factual\"\n",
        "    COMPLEX_REASONING = \"complex_reasoning\"\n",
        "    COMPARISON = \"comparison\"\n",
        "    MULTI_HOP = \"multi_hop\"\n",
        "    SUMMARIZATION = \"summarization\"\n",
        "\n",
        "\n",
        "class QueryClassification(BaseModel):\n",
        "    query_type: QueryType = Field(description=\"Type of query\")\n",
        "    complexity: int = Field(description=\"Complexity score from 1-10\")\n",
        "    requires_decomposition: bool = Field(description=\"Whether query needs to be broken down\")\n",
        "    reasoning: str = Field(description=\"Explanation of classification\")\n",
        "\n",
        "\n",
        "class SubQuery(BaseModel):\n",
        "    question: str = Field(description=\"The sub-question\")\n",
        "    order: int = Field(description=\"Order of execution\")\n",
        "    dependencies: List[int] = Field(default=[], description=\"Indices of queries this depends on\")\n",
        "\n",
        "\n",
        "class QueryDecomposition(BaseModel):\n",
        "    sub_queries: List[SubQuery] = Field(description=\"List of sub-queries\")\n",
        "    synthesis_instruction: str = Field(description=\"How to combine answers\")\n",
        "\n",
        "\n",
        "class RetrievalEvaluation(BaseModel):\n",
        "    is_sufficient: bool = Field(description=\"Are documents sufficient to answer?\")\n",
        "    relevance_scores: List[float] = Field(description=\"Relevance score for each document\")\n",
        "    missing_info: Optional[str] = Field(description=\"What information is missing if insufficient\")\n",
        "    confidence: float = Field(description=\"Confidence in evaluation (0-1)\")\n",
        "\n",
        "\n",
        "class GenerationEvaluation(BaseModel):\n",
        "    is_accurate: bool = Field(description=\"Is the answer accurate?\")\n",
        "    is_complete: bool = Field(description=\"Is the answer complete?\")\n",
        "    is_grounded: bool = Field(description=\"Is answer grounded in retrieved docs?\")\n",
        "    needs_refinement: bool = Field(description=\"Does answer need refinement?\")\n",
        "    issues: List[str] = Field(default=[], description=\"List of issues if any\")\n",
        "    confidence: float = Field(description=\"Confidence score (0-1)\")"
      ],
      "metadata": {
        "id": "Rr4zksvZrE7c"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_CLASSIFICATION_PROMPT = \"\"\"Analyze the following user query and classify it.\n",
        "\n",
        "User Query: {query}\n",
        "\n",
        "Classify based on:\n",
        "1. Query Type: simple_factual, complex_reasoning, comparison, multi_hop, summarization\n",
        "2. Complexity: Rate from 1-10\n",
        "3. Whether it requires decomposition into sub-queries\n",
        "4. Provide reasoning for your classification\n",
        "\n",
        "Respond ONLY with valid JSON in this exact format (no markdown, no extra text):\n",
        "{{\n",
        "    \"query_type\": \"simple_factual\",\n",
        "    \"complexity\": 5,\n",
        "    \"requires_decomposition\": false,\n",
        "    \"reasoning\": \"explanation here\"\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "QUERY_DECOMPOSITION_PROMPT = \"\"\"Decompose this complex query into simpler sub-queries.\n",
        "\n",
        "User Query: {query}\n",
        "\n",
        "Create sub-queries that:\n",
        "1. Can be answered independently or with minimal dependencies\n",
        "2. Are ordered logically\n",
        "3. Together provide information to answer the original query\n",
        "\n",
        "Respond ONLY with valid JSON (no markdown, no extra text):\n",
        "{{\n",
        "    \"sub_queries\": [\n",
        "        {{\"question\": \"sub-question 1\", \"order\": 1, \"dependencies\": []}},\n",
        "        {{\"question\": \"sub-question 2\", \"order\": 2, \"dependencies\": [1]}}\n",
        "    ],\n",
        "    \"synthesis_instruction\": \"How to combine the answers\"\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "RETRIEVAL_EVALUATION_PROMPT = \"\"\"Evaluate if these retrieved documents are sufficient to answer the query.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Retrieved Documents:\n",
        "{docs_text}\n",
        "\n",
        "Evaluate:\n",
        "1. Are documents sufficient? (true/false)\n",
        "2. Relevance score for each document (0-1)\n",
        "3. What information is missing if insufficient?\n",
        "4. Confidence in your evaluation (0-1)\n",
        "\n",
        "Respond ONLY with valid JSON (no markdown, no extra text):\n",
        "{{\n",
        "    \"is_sufficient\": true,\n",
        "    \"relevance_scores\": [0.9, 0.8, 0.7, 0.6, 0.5],\n",
        "    \"missing_info\": null,\n",
        "    \"confidence\": 0.85\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "ANSWER_GENERATION_PROMPT = \"\"\"Answer the following question based ONLY on the provided documents.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Retrieved Documents:\n",
        "{docs_text}{context_str}\n",
        "\n",
        "Instructions:\n",
        "1. Provide a comprehensive answer based on the documents\n",
        "2. Cite specific documents when making claims\n",
        "3. If documents don't contain enough information, explicitly state what's missing\n",
        "4. Be precise and factual\n",
        "5. Do not add information not present in the documents\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "\n",
        "GENERATION_EVALUATION_PROMPT = \"\"\"Evaluate the quality of this generated answer.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Generated Answer:\n",
        "{answer}\n",
        "\n",
        "Source Documents:\n",
        "{docs_text}\n",
        "\n",
        "Evaluate:\n",
        "1. Is the answer accurate based on documents? (true/false)\n",
        "2. Is the answer complete? (true/false)\n",
        "3. Is the answer grounded in the documents (no hallucinations)? (true/false)\n",
        "4. Does it need refinement? (true/false)\n",
        "5. List any issues found\n",
        "6. Confidence score (0-1)\n",
        "\n",
        "Respond ONLY with valid JSON (no markdown, no extra text):\n",
        "{{\n",
        "    \"is_accurate\": true,\n",
        "    \"is_complete\": true,\n",
        "    \"is_grounded\": true,\n",
        "    \"needs_refinement\": false,\n",
        "    \"issues\": [],\n",
        "    \"confidence\": 0.9\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "ANSWER_REFINEMENT_PROMPT = \"\"\"Refine the following answer to address the identified issues.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Initial Answer:\n",
        "{initial_answer}\n",
        "\n",
        "Issues Identified:\n",
        "{issues_text}\n",
        "\n",
        "Source Documents:\n",
        "{docs_text}\n",
        "\n",
        "Instructions:\n",
        "1. Address each issue mentioned\n",
        "2. Ensure answer is grounded in documents\n",
        "3. Improve completeness and accuracy\n",
        "4. Maintain clarity and coherence\n",
        "\n",
        "Refined Answer:\"\"\""
      ],
      "metadata": {
        "id": "1wE5KuDoGN3z"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pathlib import Path\n",
        "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_classic.schema import Document\n",
        "# from config import RAGConfig\n",
        "\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=config.CHUNK_SIZE,\n",
        "            chunk_overlap=config.CHUNK_OVERLAP,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        "            length_function=len\n",
        "        )\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=config.EMBEDDING_MODEL\n",
        "        )\n",
        "        self.vector_store = None\n",
        "\n",
        "    def load_pdf_documents(self, pdf_paths: List[str]) -> List[Document]:\n",
        "        all_documents = []\n",
        "\n",
        "        for pdf_path in pdf_paths:\n",
        "            print(f\"Loading: {pdf_path}\")\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents = loader.load()\n",
        "\n",
        "            for doc in documents:\n",
        "                doc.metadata['source_file'] = Path(pdf_path).name\n",
        "\n",
        "            all_documents.extend(documents)\n",
        "\n",
        "        print(f\"Loaded {len(all_documents)} pages from {len(pdf_paths)} PDFs\")\n",
        "        return all_documents\n",
        "\n",
        "    def chunk_documents(self, documents: List[Document]) -> List[Document]:\n",
        "        chunks = self.text_splitter.split_documents(documents)\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            chunk.metadata['chunk_id'] = i\n",
        "\n",
        "        print(f\"Created {len(chunks)} chunks\")\n",
        "        return chunks\n",
        "\n",
        "    def create_vector_store(self, chunks: List[Document]) -> None:\n",
        "        if self.config.VECTOR_DB_TYPE == \"chroma\":\n",
        "            self.vector_store = Chroma.from_documents(\n",
        "                documents=chunks,\n",
        "                embedding=self.embeddings,\n",
        "                collection_name=self.config.COLLECTION_NAME,\n",
        "                persist_directory=self.config.PERSIST_DIRECTORY\n",
        "            )\n",
        "            self.vector_store.persist()\n",
        "        else:\n",
        "            self.vector_store = FAISS.from_documents(\n",
        "                documents=chunks,\n",
        "                embedding=self.embeddings\n",
        "            )\n",
        "            self.vector_store.save_local(self.config.PERSIST_DIRECTORY)\n",
        "\n",
        "        print(f\"Vector store created with {len(chunks)} chunks\")\n",
        "\n",
        "    def load_existing_vector_store(self) -> None:\n",
        "        if self.config.VECTOR_DB_TYPE == \"chroma\":\n",
        "            self.vector_store = Chroma(\n",
        "                collection_name=self.config.COLLECTION_NAME,\n",
        "                embedding_function=self.embeddings,\n",
        "                persist_directory=self.config.PERSIST_DIRECTORY\n",
        "            )\n",
        "        else:\n",
        "            self.vector_store = FAISS.load_local(\n",
        "                self.config.PERSIST_DIRECTORY,\n",
        "                self.embeddings\n",
        "            )\n",
        "\n",
        "        print(\"Loaded existing vector store\")\n",
        "\n",
        "    def process_and_store(self, pdf_paths: List[str]) -> None:\n",
        "        documents = self.load_pdf_documents(pdf_paths)\n",
        "        chunks = self.chunk_documents(documents)\n",
        "        self.create_vector_store(chunks)"
      ],
      "metadata": {
        "id": "DFw2_QoM8wm0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any\n",
        "import json\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_classic.schema import Document\n",
        "from langchain_openai import ChatOpenAI\n",
        "# from config import RAGConfig\n",
        "# from models import (\n",
        "#     QueryClassification, QueryDecomposition,\n",
        "#     RetrievalEvaluation, GenerationEvaluation\n",
        "# )\n",
        "# from prompts import (\n",
        "#     QUERY_CLASSIFICATION_PROMPT, QUERY_DECOMPOSITION_PROMPT,\n",
        "#     RETRIEVAL_EVALUATION_PROMPT, ANSWER_GENERATION_PROMPT,\n",
        "#     GENERATION_EVALUATION_PROMPT, ANSWER_REFINEMENT_PROMPT\n",
        "# )\n",
        "\n",
        "\n",
        "class AgenticRAG:\n",
        "    def __init__(self, config: RAGConfig, vector_store):\n",
        "        self.config = config\n",
        "        self.vector_store = vector_store\n",
        "\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=config.LLM_MODEL,\n",
        "            openai_api_key=config.OPENAI_API_KEY,\n",
        "            openai_api_base=config.BASE_URL,\n",
        "            temperature=config.LLM_TEMPERATURE,\n",
        "            max_tokens=1024,\n",
        "            default_headers={\n",
        "                \"HTTP-Referer\": \"https://company-chatbot.local\",\n",
        "                \"X-Title\": \"Multi-Agent System\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=config.EMBEDDING_MODEL\n",
        "        )\n",
        "\n",
        "    def _clean_json_response(self, content: str) -> str:\n",
        "        content = content.strip()\n",
        "        if content.startswith(\"```json\"):\n",
        "            content = content[7:]\n",
        "        if content.startswith(\"```\"):\n",
        "            content = content[3:]\n",
        "        if content.endswith(\"```\"):\n",
        "            content = content[:-3]\n",
        "        return content.strip()\n",
        "\n",
        "    def classify_query(self, query: str) -> QueryClassification:\n",
        "        prompt = QUERY_CLASSIFICATION_PROMPT.format(query=query)\n",
        "        response = self.llm.invoke(prompt)\n",
        "        content = self._clean_json_response(response.content)\n",
        "\n",
        "        try:\n",
        "            result = json.loads(content)\n",
        "            return QueryClassification(**result)\n",
        "        except json.JSONDecodeError:\n",
        "            return QueryClassification(\n",
        "                query_type=\"simple_factual\",\n",
        "                complexity=5,\n",
        "                requires_decomposition=False,\n",
        "                reasoning=\"Default classification due to parsing error\"\n",
        "            )\n",
        "\n",
        "    def decompose_query(self, query: str) -> QueryDecomposition:\n",
        "        prompt = QUERY_DECOMPOSITION_PROMPT.format(query=query)\n",
        "        response = self.llm.invoke(prompt)\n",
        "        content = self._clean_json_response(response.content)\n",
        "\n",
        "        try:\n",
        "            result = json.loads(content)\n",
        "            return QueryDecomposition(**result)\n",
        "        except json.JSONDecodeError:\n",
        "            return QueryDecomposition(\n",
        "                sub_queries=[],\n",
        "                synthesis_instruction=\"Combine answers sequentially\"\n",
        "            )\n",
        "\n",
        "    def retrieve_documents(self, query: str, k: int = None) -> List[Document]:\n",
        "        k = k or self.config.TOP_K_DOCUMENTS\n",
        "        docs = self.vector_store.similarity_search(query, k=k)\n",
        "        return docs\n",
        "\n",
        "    def retrieve_with_scores(self, query: str, k: int = None) -> List[tuple]:\n",
        "        k = k or self.config.TOP_K_DOCUMENTS\n",
        "        docs_with_scores = self.vector_store.similarity_search_with_score(query, k=k)\n",
        "        return docs_with_scores\n",
        "\n",
        "    def evaluate_retrieval(self, query: str, documents: List[Document]) -> RetrievalEvaluation:\n",
        "        docs_text = \"\\n\\n\".join([\n",
        "            f\"Document {i+1}:\\n{doc.page_content[:500]}...\"\n",
        "            for i, doc in enumerate(documents)\n",
        "        ])\n",
        "\n",
        "        prompt = RETRIEVAL_EVALUATION_PROMPT.format(\n",
        "            query=query,\n",
        "            docs_text=docs_text\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt)\n",
        "        content = self._clean_json_response(response.content)\n",
        "\n",
        "        try:\n",
        "            result = json.loads(content)\n",
        "            return RetrievalEvaluation(**result)\n",
        "        except json.JSONDecodeError:\n",
        "            return RetrievalEvaluation(\n",
        "                is_sufficient=True,\n",
        "                relevance_scores=[0.5] * len(documents),\n",
        "                missing_info=None,\n",
        "                confidence=0.5\n",
        "            )\n",
        "\n",
        "    def generate_answer(self, query: str, documents: List[Document],\n",
        "                       context: Dict[str, Any] = None) -> str:\n",
        "        docs_text = \"\\n\\n\".join([\n",
        "            f\"Document {i+1} (Source: {doc.metadata.get('source_file', 'unknown')}):\\n{doc.page_content}\"\n",
        "            for i, doc in enumerate(documents)\n",
        "        ])\n",
        "\n",
        "        context_str = \"\"\n",
        "        if context:\n",
        "            context_str = f\"\\n\\nAdditional Context:\\n{json.dumps(context, indent=2)}\"\n",
        "\n",
        "        prompt = ANSWER_GENERATION_PROMPT.format(\n",
        "            query=query,\n",
        "            docs_text=docs_text,\n",
        "            context_str=context_str\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt)\n",
        "        return response.content\n",
        "\n",
        "    def evaluate_generation(self, query: str, answer: str,\n",
        "                           documents: List[Document]) -> GenerationEvaluation:\n",
        "        docs_text = \"\\n\\n\".join([\n",
        "            f\"Doc {i+1}: {doc.page_content[:300]}...\"\n",
        "            for i, doc in enumerate(documents)\n",
        "        ])\n",
        "\n",
        "        prompt = GENERATION_EVALUATION_PROMPT.format(\n",
        "            query=query,\n",
        "            answer=answer,\n",
        "            docs_text=docs_text\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt)\n",
        "        content = self._clean_json_response(response.content)\n",
        "\n",
        "        try:\n",
        "            result = json.loads(content)\n",
        "            return GenerationEvaluation(**result)\n",
        "        except json.JSONDecodeError:\n",
        "            return GenerationEvaluation(\n",
        "                is_accurate=True,\n",
        "                is_complete=True,\n",
        "                is_grounded=True,\n",
        "                needs_refinement=False,\n",
        "                issues=[],\n",
        "                confidence=0.8\n",
        "            )\n",
        "\n",
        "    def refine_answer(self, query: str, initial_answer: str,\n",
        "                     documents: List[Document], evaluation: GenerationEvaluation) -> str:\n",
        "        docs_text = \"\\n\\n\".join([\n",
        "            f\"Doc {i+1}: {doc.page_content}\"\n",
        "            for i, doc in enumerate(documents)\n",
        "        ])\n",
        "\n",
        "        issues_text = \"\\n\".join([f\"- {issue}\" for issue in evaluation.issues])\n",
        "\n",
        "        prompt = ANSWER_REFINEMENT_PROMPT.format(\n",
        "            query=query,\n",
        "            initial_answer=initial_answer,\n",
        "            issues_text=issues_text,\n",
        "            docs_text=docs_text\n",
        "        )\n",
        "\n",
        "        response = self.llm.invoke(prompt)\n",
        "        return response.content\n",
        "\n",
        "    def process_query(self, query: str, verbose: bool = True) -> Dict[str, Any]:\n",
        "        result = {\n",
        "            \"query\": query,\n",
        "            \"classification\": None,\n",
        "            \"decomposition\": None,\n",
        "            \"sub_results\": [],\n",
        "            \"retrieved_documents\": [],\n",
        "            \"retrieval_evaluation\": None,\n",
        "            \"initial_answer\": None,\n",
        "            \"generation_evaluation\": None,\n",
        "            \"final_answer\": None,\n",
        "            \"iterations\": 0,\n",
        "            \"metadata\": {}\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"STEP 1: QUERY CLASSIFICATION\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        classification = self.classify_query(query)\n",
        "        result[\"classification\"] = classification.dict()\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Query Type: {classification.query_type}\")\n",
        "            print(f\"Complexity: {classification.complexity}/10\")\n",
        "            print(f\"Requires Decomposition: {classification.requires_decomposition}\")\n",
        "            print(f\"Reasoning: {classification.reasoning}\")\n",
        "\n",
        "        if classification.requires_decomposition and self.config.ENABLE_QUERY_DECOMPOSITION:\n",
        "            if verbose:\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"STEP 2: QUERY DECOMPOSITION\")\n",
        "                print(\"=\"*70)\n",
        "\n",
        "            decomposition = self.decompose_query(query)\n",
        "            result[\"decomposition\"] = decomposition.dict()\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Decomposed into {len(decomposition.sub_queries)} sub-queries:\")\n",
        "                for sq in decomposition.sub_queries:\n",
        "                    print(f\"  {sq.order}. {sq.question}\")\n",
        "\n",
        "            sub_answers = {}\n",
        "            for sub_query in sorted(decomposition.sub_queries, key=lambda x: x.order):\n",
        "                if verbose:\n",
        "                    print(f\"\\n  Processing sub-query {sub_query.order}: {sub_query.question}\")\n",
        "\n",
        "                sub_docs = self.retrieve_documents(sub_query.question, k=3)\n",
        "                sub_answer = self.generate_answer(sub_query.question, sub_docs)\n",
        "                sub_answers[sub_query.order] = sub_answer\n",
        "\n",
        "                result[\"sub_results\"].append({\n",
        "                    \"sub_query\": sub_query.question,\n",
        "                    \"answer\": sub_answer\n",
        "                })\n",
        "\n",
        "            synthesis_context = {\n",
        "                \"sub_answers\": sub_answers,\n",
        "                \"synthesis_instruction\": decomposition.synthesis_instruction\n",
        "            }\n",
        "\n",
        "            documents = self.retrieve_documents(query)\n",
        "            result[\"retrieved_documents\"] = [doc.page_content for doc in documents]\n",
        "            answer = self.generate_answer(query, documents, context=synthesis_context)\n",
        "\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"STEP 2: DOCUMENT RETRIEVAL\")\n",
        "                print(\"=\"*70)\n",
        "\n",
        "            documents = self.retrieve_documents(query)\n",
        "            result[\"retrieved_documents\"] = [doc.page_content for doc in documents]\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Retrieved {len(documents)} documents\")\n",
        "\n",
        "            if verbose:\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"STEP 3: RETRIEVAL EVALUATION\")\n",
        "                print(\"=\"*70)\n",
        "\n",
        "            retrieval_eval = self.evaluate_retrieval(query, documents)\n",
        "            result[\"retrieval_evaluation\"] = retrieval_eval.dict()\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Sufficient: {retrieval_eval.is_sufficient}\")\n",
        "                print(f\"Confidence: {retrieval_eval.confidence}\")\n",
        "                if not retrieval_eval.is_sufficient:\n",
        "                    print(f\"Missing Info: {retrieval_eval.missing_info}\")\n",
        "\n",
        "            if verbose:\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"STEP 4: ANSWER GENERATION\")\n",
        "                print(\"=\"*70)\n",
        "\n",
        "            answer = self.generate_answer(query, documents)\n",
        "\n",
        "        result[\"initial_answer\"] = answer\n",
        "\n",
        "        if self.config.ENABLE_SELF_CORRECTION:\n",
        "            if verbose:\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"STEP 5: ANSWER EVALUATION & REFINEMENT\")\n",
        "                print(\"=\"*70)\n",
        "\n",
        "            for iteration in range(self.config.MAX_ITERATIONS):\n",
        "                result[\"iterations\"] = iteration + 1\n",
        "\n",
        "                gen_eval = self.evaluate_generation(query, answer, documents)\n",
        "                result[\"generation_evaluation\"] = gen_eval.dict()\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"\\nIteration {iteration + 1}:\")\n",
        "                    print(f\"  Accurate: {gen_eval.is_accurate}\")\n",
        "                    print(f\"  Complete: {gen_eval.is_complete}\")\n",
        "                    print(f\"  Grounded: {gen_eval.is_grounded}\")\n",
        "                    print(f\"  Confidence: {gen_eval.confidence}\")\n",
        "\n",
        "                if not gen_eval.needs_refinement or gen_eval.confidence > 0.9:\n",
        "                    if verbose:\n",
        "                        print(\"   Answer quality satisfactory!\")\n",
        "                    break\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"  Issues: {gen_eval.issues}\")\n",
        "                    print(\"  Refining answer...\")\n",
        "\n",
        "                answer = self.refine_answer(query, answer, documents, gen_eval)\n",
        "\n",
        "        result[\"final_answer\"] = answer\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"FINAL ANSWER\")\n",
        "            print(\"=\"*70)\n",
        "            print(answer)\n",
        "            print(\"\\n\")\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "fUvTAGnK9HRM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# from config import RAGConfig\n",
        "# from document_processor import DocumentProcessor\n",
        "# from agentic_rag import AgenticRAG\n",
        "\n",
        "\n",
        "def setup_system(pdf_files: list[str], rebuild_db: bool = False):\n",
        "    print(\"=\"*70)\n",
        "    print(\"AGENTIC RAG SYSTEM - INITIALIZATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    config = RAGConfig()\n",
        "\n",
        "    print(\"\\n Setting up document processor...\")\n",
        "    processor = DocumentProcessor(config)\n",
        "\n",
        "    if rebuild_db:\n",
        "        print(\"\\n Building vector database...\")\n",
        "        processor.process_and_store(pdf_files)\n",
        "    else:\n",
        "        print(\"\\n Loading existing vector database...\")\n",
        "        processor.load_existing_vector_store()\n",
        "\n",
        "    print(\"\\n Initializing Agentic RAG system...\")\n",
        "    rag = AgenticRAG(config, processor.vector_store)\n",
        "\n",
        "    print(\"\\n System ready!\")\n",
        "    return rag, processor\n",
        "\n",
        "\n",
        "def run_example_query(rag: AgenticRAG):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXAMPLE QUERY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    query = \"What is the main topic discussed in the document?\"\n",
        "    result = rag.process_query(query, verbose=True)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def interactive_mode(rag: AgenticRAG):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"INTERACTIVE MODE\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Enter your questions (type 'exit' to quit, 'help' for options)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    verbose = True\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\n Your question: \").strip()\n",
        "\n",
        "        if query.lower() == 'exit':\n",
        "            print(\" Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if query.lower() == 'help':\n",
        "            print(\"\\nCommands:\")\n",
        "            print(\"  exit - Exit interactive mode\")\n",
        "            print(\"  help - Show this help message\")\n",
        "            print(\"  verbose on - Enable verbose output\")\n",
        "            print(\"  verbose off - Disable verbose output\")\n",
        "            continue\n",
        "\n",
        "        if query.lower() == 'verbose on':\n",
        "            verbose = True\n",
        "            print(\" Verbose mode enabled\")\n",
        "            continue\n",
        "\n",
        "        if query.lower() == 'verbose off':\n",
        "            verbose = False\n",
        "            print(\" Verbose mode disabled\")\n",
        "            continue\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        result = rag.process_query(query, verbose=verbose)\n",
        "\n",
        "\n",
        "def main():\n",
        "    pdf_files = [\n",
        "        \"./Umair_Ali.pdf\"\n",
        "    ]\n",
        "\n",
        "    rag_system, doc_processor = setup_system(pdf_files, rebuild_db=False)\n",
        "\n",
        "    run_example_query(rag_system)\n",
        "\n",
        "    interactive_mode(rag_system)\n",
        "\n",
        "    print(\"\\n Agentic RAG system demonstration complete!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGDsOuo59ZUk",
        "outputId": "e7c2c1fc-2d69-478b-819f-c9234d8f4ec6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "AGENTIC RAG SYSTEM - INITIALIZATION\n",
            "======================================================================\n",
            "\n",
            " Setting up document processor...\n",
            "\n",
            " Loading existing vector database...\n",
            "Loaded existing vector store\n",
            "\n",
            " Initializing Agentic RAG system...\n",
            "\n",
            " System ready!\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE QUERY\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STEP 1: QUERY CLASSIFICATION\n",
            "======================================================================\n",
            "Query Type: QueryType.SIMPLE_FACTUAL\n",
            "Complexity: 5/10\n",
            "Requires Decomposition: False\n",
            "Reasoning: Default classification due to parsing error\n",
            "\n",
            "======================================================================\n",
            "STEP 2: DOCUMENT RETRIEVAL\n",
            "======================================================================\n",
            "Retrieved 0 documents\n",
            "\n",
            "======================================================================\n",
            "STEP 3: RETRIEVAL EVALUATION\n",
            "======================================================================\n",
            "Sufficient: True\n",
            "Confidence: 0.85\n",
            "\n",
            "======================================================================\n",
            "STEP 4: ANSWER GENERATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STEP 5: ANSWER EVALUATION & REFINEMENT\n",
            "======================================================================\n",
            "\n",
            "Iteration 1:\n",
            "  Accurate: True\n",
            "  Complete: True\n",
            "  Grounded: True\n",
            "  Confidence: 0.8\n",
            "   Answer quality satisfactory!\n",
            "\n",
            "======================================================================\n",
            "FINAL ANSWER\n",
            "======================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "======================================================================\n",
            "INTERACTIVE MODE\n",
            "======================================================================\n",
            "Enter your questions (type 'exit' to quit, 'help' for options)\n",
            "======================================================================\n",
            "\n",
            " Your question: what is the experience of applier \n",
            "\n",
            "======================================================================\n",
            "STEP 1: QUERY CLASSIFICATION\n",
            "======================================================================\n",
            "Query Type: QueryType.SIMPLE_FACTUAL\n",
            "Complexity: 4/10\n",
            "Requires Decomposition: False\n",
            "Reasoning: The query asks for a direct factual answer without requiring complex analysis.\n",
            "\n",
            "======================================================================\n",
            "STEP 2: DOCUMENT RETRIEVAL\n",
            "======================================================================\n",
            "Retrieved 0 documents\n",
            "\n",
            "======================================================================\n",
            "STEP 3: RETRIEVAL EVALUATION\n",
            "======================================================================\n",
            "Sufficient: True\n",
            "Confidence: 0.5\n",
            "\n",
            "======================================================================\n",
            "STEP 4: ANSWER GENERATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STEP 5: ANSWER EVALUATION & REFINEMENT\n",
            "======================================================================\n",
            "\n",
            "Iteration 1:\n",
            "  Accurate: True\n",
            "  Complete: True\n",
            "  Grounded: True\n",
            "  Confidence: 0.8\n",
            "   Answer quality satisfactory!\n",
            "\n",
            "======================================================================\n",
            "FINAL ANSWER\n",
            "======================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Your question: quit\n",
            "\n",
            "======================================================================\n",
            "STEP 1: QUERY CLASSIFICATION\n",
            "======================================================================\n",
            "Query Type: QueryType.SIMPLE_FACTUAL\n",
            "Complexity: 5/10\n",
            "Requires Decomposition: False\n",
            "Reasoning: Default classification due to parsing error\n",
            "\n",
            "======================================================================\n",
            "STEP 2: DOCUMENT RETRIEVAL\n",
            "======================================================================\n",
            "Retrieved 0 documents\n",
            "\n",
            "======================================================================\n",
            "STEP 3: RETRIEVAL EVALUATION\n",
            "======================================================================\n",
            "Sufficient: True\n",
            "Confidence: 0.5\n",
            "\n",
            "======================================================================\n",
            "STEP 4: ANSWER GENERATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STEP 5: ANSWER EVALUATION & REFINEMENT\n",
            "======================================================================\n",
            "\n",
            "Iteration 1:\n",
            "  Accurate: True\n",
            "  Complete: True\n",
            "  Grounded: True\n",
            "  Confidence: 0.8\n",
            "   Answer quality satisfactory!\n",
            "\n",
            "======================================================================\n",
            "FINAL ANSWER\n",
            "======================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Your question: exit\n",
            " Goodbye!\n",
            "\n",
            " Agentic RAG system demonstration complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}